{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "eta = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mnist.pkl.gz'\n",
    "f = gzip.open(filename, 'rb')\n",
    "training_data, validation_data, test_data = pickle.load(f, encoding='latin1')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load USPS on Python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "USPSMat  = []\n",
    "USPSTar  = []\n",
    "curPath  = 'USPSdata/Numerals'\n",
    "savedImg = []\n",
    "\n",
    "for j in range(0,10):\n",
    "    curFolderPath = curPath + '/' + str(j)\n",
    "    imgs =  os.listdir(curFolderPath)\n",
    "    for img in imgs:\n",
    "        curImg = curFolderPath + '/' + img\n",
    "        if curImg[-3:] == 'png':\n",
    "            img = Image.open(curImg,'r')\n",
    "            img = img.resize((28, 28))\n",
    "            savedImg = img\n",
    "            imgdata = (255-np.array(img.getdata()))/255\n",
    "            USPSMat.append(imgdata)\n",
    "            USPSTar.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one hot vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1].shape[0]\n",
    "onehotvector = np.zeros((50000,10))\n",
    "for i in range(50000):\n",
    "    if(training_data[1][i] ==0):\n",
    "        onehotvector[i] = [1,0,0,0,0,0,0,0,0,0]\n",
    "    if(training_data[1][i] ==1):\n",
    "        onehotvector[i] = [0,1,0,0,0,0,0,0,0,0]\n",
    "    if(training_data[1][i] ==2):\n",
    "        onehotvector[i] = [0,0,1,0,0,0,0,0,0,0] \n",
    "    if(training_data[1][i] ==3):\n",
    "        onehotvector[i] = [0,0,0,1,0,0,0,0,0,0]\n",
    "    if(training_data[1][i] ==4):\n",
    "        onehotvector[i] = [0,0,0,0,1,0,0,0,0,0]\n",
    "    if(training_data[1][i] ==5):\n",
    "        onehotvector[i] = [0,0,0,0,0,1,0,0,0,0]\n",
    "    if(training_data[1][i] ==6):\n",
    "        onehotvector[i] = [0,0,0,0,0,0,1,0,0,0]\n",
    "    if(training_data[1][i] ==7):\n",
    "        onehotvector[i] = [0,0,0,0,0,0,0,1,0,0]\n",
    "        \n",
    "    if(training_data[1][i] ==8):\n",
    "        onehotvector[i] = [0,0,0,0,0,0,0,0,1,0]\n",
    "    if(training_data[1][i] ==9):\n",
    "        onehotvector[i] = [0,0,0,0,0,0,0,0,0,1]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "onehotvector[49000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    sum_ex = np.sum( np.exp(x))\n",
    "    return ex/sum_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialiazing of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wnew = np.random.rand(10,784)/10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b = [1,1,1,1,1,1,1,1,1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(50000):\n",
    "    z = np.dot(wnew,training_data[0][i]) + b\n",
    "    s = softmax(z)\n",
    "    #k = values.index(max(s))\n",
    "    delE = np.dot(np.transpose((s - onehotvector[i])[np.newaxis]),(training_data[0][i][np.newaxis]))\n",
    "    wnew = wnew - eta*delE\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.24\n"
     ]
    }
   ],
   "source": [
    "testdata = test_data[0]\n",
    "#testonehotvector = np.zeros((10000,10))\n",
    "right = 0\n",
    "wrong = 0\n",
    "for i in range(50000):\n",
    "    z = np.dot(wnew,training_data[0][i]) \n",
    "    s = softmax(z)\n",
    "    m = np.argmax(s)\n",
    "    if (m == training_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = (right/50000)*100\n",
    "\n",
    "print(accuracy)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.21000000000001\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "for i in range(10000):\n",
    "    z = np.dot(wnew,validation_data[0][i]) \n",
    "    s = softmax(z)\n",
    "    m = np.argmax(s)\n",
    "    if (m == validation_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = (right/10000)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.79\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "predlog = []\n",
    "for i in range(10000):\n",
    "    z = np.dot(wnew,test_data[0][i]) \n",
    "    s = softmax(z)\n",
    "    m = np.argmax(s)\n",
    "    predlog.append(m)\n",
    "    if (m == test_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = (right/10000)*100\n",
    "\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 955,    0,    1,    4,    0,    5,    9,    1,    5,    0],\n",
       "       [   0, 1113,    0,    5,    0,    3,    4,    2,    8,    0],\n",
       "       [   9,    9,  881,   31,   11,    3,   13,   24,   43,    8],\n",
       "       [   2,    0,   11,  927,    0,   37,    1,   12,   12,    8],\n",
       "       [   2,    4,    4,    1,  887,    1,   12,    4,   10,   57],\n",
       "       [   8,    5,    1,   44,    6,  775,   10,    9,   26,    8],\n",
       "       [  12,    3,    3,    3,    8,   29,  892,    3,    5,    0],\n",
       "       [   2,   14,   19,    8,    5,    0,    0,  951,    3,   26],\n",
       "       [   3,   10,    4,   46,    7,   55,   12,   16,  808,   13],\n",
       "       [   8,    8,    2,   13,   20,   19,    0,   40,    4,  895]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true =test_data[1]  \n",
    ">>> y_predict = predlog\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing accuracy on USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.24176208810441\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "predlogU = []\n",
    "for i in range(19999):\n",
    "    z = np.dot(wnew,USPSMat[i]) \n",
    "    s = softmax(z)\n",
    "    m = np.argmax(s)\n",
    "    predlogU.append(m)\n",
    "    if (m == USPSTar[i]):\n",
    "            right = right + 1\n",
    "accuracy = (right/19999)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 563,    4,  255,   84,  167,  238,   95,   88,  146,  360],\n",
       "       [ 159,  356,  161,  341,  153,  108,   29,  464,  202,   27],\n",
       "       [ 173,   21, 1101,  233,   37,  149,   87,   85,   81,   32],\n",
       "       [  59,    2,  108, 1337,    3,  331,    3,   67,   56,   34],\n",
       "       [  64,   81,   32,   75,  833,  169,   46,  210,  321,  169],\n",
       "       [ 134,   19,  162,  210,   24, 1232,   82,   72,   48,   17],\n",
       "       [ 262,   10,  334,  147,   65,  396,  677,   26,   41,   42],\n",
       "       [ 161,  200,  216,  523,   58,  116,   22,  368,  276,   60],\n",
       "       [ 222,   32,  116,  248,   76,  737,  102,   56,  343,   68],\n",
       "       [  30,  144,  111,  526,   88,  112,   14,  460,  336,  179]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true =USPSTar  \n",
    ">>> y_predict = predlogU\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = wnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini batch size SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mini-Batch SGD Logistic Regression\n",
    "wt = np.random.rand(10,784)/10000\n",
    "batchsize = 50\n",
    "epoch = 20\n",
    "sum = 0\n",
    "for j in range(epoch):\n",
    "    for i in range(len(training_data[0])):\n",
    "        z = np.dot(wt,training_data[0][i]) + b \n",
    "        y = softmax(z)\n",
    "        E = np.dot(np.transpose((y-onehotvector[i])[np.newaxis]),training_data[0][i][np.newaxis])\n",
    "        sum = sum + E\n",
    "        if((i+1)%batchsize==0):\n",
    "            wt = wt - eta*(sum/batchsize)\n",
    "            sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 90.33\n"
     ]
    }
   ],
   "source": [
    "y_pred_lr =[]\n",
    "right = 0\n",
    "wrong = 0\n",
    "for i in range(len(test_data[0])):\n",
    "    z = np.dot(wt,test_data[0][i])\n",
    "    y = softmax(z)\n",
    "    y_pred_lr.append(np.argmax(y))\n",
    "    if(np.argmax(y)==test_data[1][i]):\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "    \n",
    "testacc = (right/(right+wrong))*100\n",
    "print(\"Testing Accuracy : \"+ str(testacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : 35.161758087904396\n"
     ]
    }
   ],
   "source": [
    "y_pred_lru =[]\n",
    "right = 0\n",
    "wrong = 0\n",
    "for i in range(len(USPSMat)):\n",
    "    z = np.dot(wt,USPSMat[i])\n",
    "    y = softmax(z)\n",
    "    y_pred_lru.append(np.argmax(y))\n",
    "    if(np.argmax(y)==USPSTar[i]):\n",
    "        right = right + 1\n",
    "    else:\n",
    "        wrong = wrong + 1\n",
    "    \n",
    "testacc = (right/(right+wrong))*100\n",
    "print(\"Testing Accuracy : \"+ str(testacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine with default gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "classifier1 = SVC(kernel='rbf', gamma = 'auto')\n",
    "classifier1.fit(training_data[0], training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier1.predict(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9435\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "for i in range(10000):\n",
    "    \n",
    "    if (y_pred[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = right/10000\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 967,    0,    1,    0,    0,    5,    4,    1,    2,    0],\n",
       "       [   0, 1120,    2,    3,    0,    1,    3,    1,    5,    0],\n",
       "       [   9,    1,  962,    7,   10,    1,   13,   11,   16,    2],\n",
       "       [   1,    1,   14,  950,    1,   17,    1,   10,   11,    4],\n",
       "       [   1,    1,    7,    0,  937,    0,    7,    2,    2,   25],\n",
       "       [   7,    4,    5,   33,    7,  808,   11,    2,   10,    5],\n",
       "       [  10,    3,    4,    1,    5,   10,  924,    0,    1,    0],\n",
       "       [   2,   13,   22,    5,    7,    1,    0,  954,    4,   20],\n",
       "       [   4,    6,    6,   14,    8,   24,   10,    8,  891,    3],\n",
       "       [  10,    6,    0,   12,   33,    5,    1,   14,    6,  922]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1] \n",
    ">>> y_predict = y_pred\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predUSVM1 = classifier1.predict(USPSMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38541927096354817\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "for i in range(19999):\n",
    "    \n",
    "    if (y_predUSVM1[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "accuracy = right/19999\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 573,    2,  428,   19,  285,  248,   73,   44,    6,  322],\n",
       "       [ 110,  429,  285,  137,  273,  180,   46,  501,   22,   17],\n",
       "       [ 128,   18, 1402,   59,   39,  198,   61,   57,   23,   14],\n",
       "       [  76,    3,  186, 1123,   11,  483,    5,   70,   27,   16],\n",
       "       [  18,   67,   91,   14, 1167,  267,   22,  194,   69,   91],\n",
       "       [ 108,   17,  257,  102,   25, 1367,   60,   43,   15,    6],\n",
       "       [ 197,    7,  489,   24,   98,  394,  748,   13,    7,   23],\n",
       "       [  50,  225,  457,  265,   57,  416,   15,  452,   41,   22],\n",
       "       [  73,   25,  209,  193,   87, 1006,   95,   41,  244,   27],\n",
       "       [  26,  166,  228,  278,  213,  165,    8,  499,  214,  203]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar \n",
    ">>> y_predict = y_predUSVM1\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine with gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# SVM\n",
    "classifier2 = SVC(kernel='rbf', gamma = 1)\n",
    "classifier2.fit(training_data[0], training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2cb647c4f38f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier2' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred2 = classifier2.predict(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right = 0\n",
    "for i in range(9999):\n",
    "    \n",
    "    if (y_pred2[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = right/9999\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1] \n",
    ">>> y_predict = y_pred2\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predUSVM2 = classifier2.predict(USPSMat)\n",
    "right = 0\n",
    "for i in range(19999):\n",
    "    \n",
    "    if (y_predUSVM2[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "accuracy = right/19999\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar \n",
    ">>> y_predict = y_predUSVM2\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine with customized gamma and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiersvm = SVC(kernel='rbf',C= 5, gamma = 0.05)\n",
    "classifiersvm.fit(training_data[0], training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predsvm = classifiersvm.predict(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9828\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "for i in range(10000):\n",
    "    \n",
    "    if (y_predsvm[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = right/10000\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 974,    0,    1,    0,    0,    1,    1,    1,    2,    0],\n",
       "       [   0, 1128,    3,    1,    0,    1,    0,    1,    1,    0],\n",
       "       [   4,    0, 1015,    1,    1,    0,    0,    6,    5,    0],\n",
       "       [   0,    0,    1,  996,    0,    4,    0,    5,    4,    0],\n",
       "       [   0,    1,    3,    0,  965,    0,    4,    0,    2,    7],\n",
       "       [   2,    0,    1,    7,    1,  872,    3,    1,    4,    1],\n",
       "       [   5,    2,    0,    0,    2,    3,  945,    0,    1,    0],\n",
       "       [   0,    3,    9,    1,    1,    0,    0, 1004,    2,    8],\n",
       "       [   2,    0,    1,    6,    1,    2,    0,    2,  958,    2],\n",
       "       [   4,    4,    2,    8,    6,    2,    0,    6,    6,  971]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1] \n",
    ">>> y_predict = y_predsvm\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26136306815340765\n"
     ]
    }
   ],
   "source": [
    "y_predUSVM3 = classifiersvm.predict(USPSMat)\n",
    "right = 0\n",
    "for i in range(19999):\n",
    "    \n",
    "    if (y_predUSVM3[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "accuracy = right/19999\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 226,    0, 1564,    2,   26,   35,    2,    0,   79,   66],\n",
       "       [  78,  257,  712,  173,  264,   77,   12,  335,   88,    4],\n",
       "       [   8,    0, 1944,    6,    3,   20,    1,    6,   11,    0],\n",
       "       [   4,    0, 1195,  725,    0,   41,    0,    0,   35,    0],\n",
       "       [   6,    0, 1045,   18,  521,   96,    0,   57,  252,    5],\n",
       "       [  15,    0, 1305,   17,    1,  625,    0,    0,   37,    0],\n",
       "       [  78,    0, 1534,    2,   10,   61,  290,    0,   22,    3],\n",
       "       [  17,    6, 1433,  129,    6,  134,    0,  222,   52,    1],\n",
       "       [   7,    0, 1387,   14,    4,  221,    0,    0,  367,    0],\n",
       "       [   1,    0, 1510,   79,   26,   29,    0,   39,  266,   50]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar \n",
    ">>> y_predict = y_predUSVM3\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "linear_svm = LinearSVC()\n",
    "linear_svm.fit(training_data[0],training_data[1])\n",
    "predsvm1 = linear_svm.predict(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    if (predsvm1[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = right/10000\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 958,    0,    2,    1,    0,    7,    8,    2,    2,    0],\n",
       "       [   0, 1113,    4,    1,    0,    1,    4,    1,   11,    0],\n",
       "       [  10,    9,  913,   22,   11,    4,   12,   10,   38,    3],\n",
       "       [   5,    2,   21,  913,    3,   20,    5,   13,   19,    9],\n",
       "       [   1,    3,    5,    3,  914,    0,   10,    3,    6,   37],\n",
       "       [  10,    3,    1,   38,   11,  762,   20,    8,   31,    8],\n",
       "       [   9,    4,    6,    2,    6,   20,  908,    1,    2,    0],\n",
       "       [   2,    8,   20,    6,    6,    1,    1,  948,    5,   31],\n",
       "       [   8,   13,    8,   23,   13,   39,    8,   15,  834,   13],\n",
       "       [   6,    8,    2,   15,   33,   10,    0,   28,   13,  894]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1]  \n",
    ">>> y_predict = predsvm1\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM on USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.321\n"
     ]
    }
   ],
   "source": [
    "predsvmU = linear_svm.predict(USPSMat)\n",
    "right = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    if (predsvmU[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = right/10000\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 307,    1,  381,  312,   60,  173,  115,  492,   59,  100],\n",
       "       [  43,  278,  664,  158,  351,   99,   28,  283,   73,   23],\n",
       "       [  70,   46, 1284,  102,   47,  170,  149,   85,   21,   25],\n",
       "       [  49,   37,  472,  749,   17,  482,   33,   83,   44,   34],\n",
       "       [  53,   53,  190,  117,  592,  178,   73,  555,  132,   57],\n",
       "       [  42,   23,  839,  218,   23,  644,   80,   96,   27,    8],\n",
       "       [  99,   12,  730,  113,   55,  334,  509,   80,   15,   53],\n",
       "       [ 128,   86,  230,  534,  115,  148,   25,  610,   84,   40],\n",
       "       [ 175,   31,  143,  662,  122,  398,  112,  202,  115,   40],\n",
       "       [  40,   51,  155,  551,  113,   73,   15,  711,  178,  113]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar \n",
    ">>> y_predict = predsvmU\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataset):\n",
    "    \n",
    "    # Why do we have to process?  We do not needvindexes, we only need values.\n",
    "    #We are converting the dataset back to array \n",
    "    #for further processing them to binary form\n",
    "    data   = dataset[0]\n",
    "    labels = onehotvector\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    print (data)\n",
    "    print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testData(dataset):\n",
    "    data   = dataset[0]\n",
    "    labels = dataset[1]\n",
    "    #to separately pass arrays to two different codes we converted the dataset to two different arrays\n",
    "    #processedData  = encodeData(data)\n",
    "    #processedLabel = encodeLabel(labels)\n",
    "    #print (data)\n",
    "    #print(labels)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/apoorvabisaria/tensorflowml/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "\n",
    "input_size = 784\n",
    "drop_out = 0.1\n",
    "first_dense_layer_nodes  = 512\n",
    "second_dense_layer = 256\n",
    "second_dense_layer_nodes = 10\n",
    "\n",
    "def get_model():\n",
    "    \n",
    "    # Why do we need a model? A model is a core data  srtucture in keras and used to organize layers.\n",
    "    # Why use Dense layer and then activation? We need to tell the system how the model is by specifying input and dense layer size,\n",
    "    #after specifying we apply activation.\n",
    "    # Why use sequential model with layers? sequential model is a linear way of stacking layers, \n",
    "    #where a layer connects just to the next layer. Here we have a fixed souce of input and output.\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(first_dense_layer_nodes, input_dim=input_size))\n",
    "    model.add(Activation('relu'))\n",
    "    #relu always gives value such that if x<0 it will give 0 otherwise it will give the number itself\n",
    "    #activation function are used to map input to output\n",
    "    \n",
    "    # Why dropout? WE used dropout to avoid overfitting of model\n",
    "    \n",
    "        \n",
    "    model.add(Dense(second_dense_layer_nodes))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Why Softmax?\n",
    "    # softmax is an activation function used when we are doing classification \n",
    "    #and softmax will give probabilities of various classes involved\n",
    "    model.summary()\n",
    "    \n",
    "    # Why use categorical_crossentropy? We use categorial cross entropy when the target is in categorical format\n",
    "    # Here we are distribuiting the number in 4 categories, thus using categorical crossentropy\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    # optimizer allows the internal learnable parameter (weights)to get adjusted.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/1500\n",
      "40000/40000 [==============================] - 3s 87us/step - loss: 0.3053 - acc: 0.9106 - val_loss: 0.1886 - val_acc: 0.9436\n",
      "Epoch 2/1500\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 0.1269 - acc: 0.9626 - val_loss: 0.1309 - val_acc: 0.9600\n",
      "Epoch 3/1500\n",
      "40000/40000 [==============================] - 3s 82us/step - loss: 0.0833 - acc: 0.9756 - val_loss: 0.1262 - val_acc: 0.9631\n",
      "Epoch 4/1500\n",
      "40000/40000 [==============================] - 3s 85us/step - loss: 0.0591 - acc: 0.9824 - val_loss: 0.1098 - val_acc: 0.9677\n",
      "Epoch 5/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 0.0433 - acc: 0.9875 - val_loss: 0.1019 - val_acc: 0.9715\n",
      "Epoch 6/1500\n",
      "40000/40000 [==============================] - 4s 88us/step - loss: 0.0321 - acc: 0.9908 - val_loss: 0.1085 - val_acc: 0.9690\n",
      "Epoch 7/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 0.0241 - acc: 0.9934 - val_loss: 0.1047 - val_acc: 0.9716\n",
      "Epoch 8/1500\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.1075 - val_acc: 0.9708\n",
      "Epoch 9/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.1075 - val_acc: 0.9718\n",
      "Epoch 10/1500\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.1070 - val_acc: 0.9740\n",
      "Epoch 11/1500\n",
      "40000/40000 [==============================] - 3s 87us/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.1325 - val_acc: 0.9696\n",
      "Epoch 12/1500\n",
      "40000/40000 [==============================] - 3s 86us/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.1269 - val_acc: 0.9739\n",
      "Epoch 13/1500\n",
      "40000/40000 [==============================] - 3s 86us/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.1163 - val_acc: 0.9742\n",
      "Epoch 14/1500\n",
      "40000/40000 [==============================] - 3s 85us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1251 - val_acc: 0.9740\n",
      "Epoch 15/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1292 - val_acc: 0.9734\n",
      "Epoch 16/1500\n",
      "40000/40000 [==============================] - 4s 97us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1446 - val_acc: 0.9725\n",
      "Epoch 17/1500\n",
      "40000/40000 [==============================] - 4s 92us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1355 - val_acc: 0.9749\n",
      "Epoch 18/1500\n",
      "40000/40000 [==============================] - 3s 82us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.1547 - val_acc: 0.9743\n",
      "Epoch 19/1500\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 8.3030e-04 - acc: 0.9998 - val_loss: 0.1577 - val_acc: 0.9729\n",
      "Epoch 20/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 6.5346e-04 - acc: 0.9998 - val_loss: 0.1561 - val_acc: 0.9737\n",
      "Epoch 21/1500\n",
      "40000/40000 [==============================] - 3s 86us/step - loss: 6.5827e-04 - acc: 0.9998 - val_loss: 0.1568 - val_acc: 0.9749\n",
      "Epoch 22/1500\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 3.3546e-04 - acc: 0.9999 - val_loss: 0.1757 - val_acc: 0.9716\n",
      "Epoch 23/1500\n",
      "40000/40000 [==============================] - 4s 98us/step - loss: 4.0306e-04 - acc: 0.9999 - val_loss: 0.1619 - val_acc: 0.9740\n",
      "Epoch 24/1500\n",
      "40000/40000 [==============================] - 3s 86us/step - loss: 4.3092e-04 - acc: 0.9999 - val_loss: 0.1642 - val_acc: 0.9748\n",
      "Epoch 25/1500\n",
      "40000/40000 [==============================] - 4s 95us/step - loss: 1.4778e-04 - acc: 1.0000 - val_loss: 0.1685 - val_acc: 0.9739\n",
      "Epoch 26/1500\n",
      "40000/40000 [==============================] - 4s 94us/step - loss: 2.6643e-04 - acc: 1.0000 - val_loss: 0.1702 - val_acc: 0.9751\n",
      "Epoch 27/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 1.0428e-04 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9734\n",
      "Epoch 28/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2619e-04 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 0.9748\n",
      "Epoch 29/1500\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.8954e-04 - acc: 1.0000 - val_loss: 0.1795 - val_acc: 0.9756\n",
      "Epoch 30/1500\n",
      "40000/40000 [==============================] - 3s 86us/step - loss: 9.2653e-05 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 0.9749\n",
      "Epoch 31/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.7534e-04 - acc: 1.0000 - val_loss: 0.1965 - val_acc: 0.9731\n",
      "Epoch 32/1500\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 4.1830e-05 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9747\n",
      "Epoch 33/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 2.9732e-05 - acc: 1.0000 - val_loss: 0.1950 - val_acc: 0.9752\n",
      "Epoch 34/1500\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 7.1491e-06 - acc: 1.0000 - val_loss: 0.1915 - val_acc: 0.9755\n",
      "Epoch 35/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2165e-05 - acc: 1.0000 - val_loss: 0.1926 - val_acc: 0.9758\n",
      "Epoch 36/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 3.9934e-06 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9755\n",
      "Epoch 37/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 4.2405e-06 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9747\n",
      "Epoch 38/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 4.7091e-07 - acc: 1.0000 - val_loss: 0.1973 - val_acc: 0.9768\n",
      "Epoch 39/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 3.2376e-07 - acc: 1.0000 - val_loss: 0.2010 - val_acc: 0.9765\n",
      "Epoch 40/1500\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 2.0859e-07 - acc: 1.0000 - val_loss: 0.2008 - val_acc: 0.9765\n",
      "Epoch 41/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.6078e-07 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9760\n",
      "Epoch 42/1500\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 1.5034e-07 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9763\n",
      "Epoch 43/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.4489e-07 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9762\n",
      "Epoch 44/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 1.4198e-07 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9761\n",
      "Epoch 45/1500\n",
      "40000/40000 [==============================] - 3s 85us/step - loss: 1.3895e-07 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9762\n",
      "Epoch 46/1500\n",
      "40000/40000 [==============================] - 4s 88us/step - loss: 1.3714e-07 - acc: 1.0000 - val_loss: 0.2014 - val_acc: 0.9763\n",
      "Epoch 47/1500\n",
      "40000/40000 [==============================] - 4s 97us/step - loss: 1.3525e-07 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9763\n",
      "Epoch 48/1500\n",
      "40000/40000 [==============================] - 4s 90us/step - loss: 1.3375e-07 - acc: 1.0000 - val_loss: 0.2020 - val_acc: 0.9763\n",
      "Epoch 49/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 1.3252e-07 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9763\n",
      "Epoch 50/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.3135e-07 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9762\n",
      "Epoch 51/1500\n",
      "40000/40000 [==============================] - 4s 95us/step - loss: 1.3032e-07 - acc: 1.0000 - val_loss: 0.2025 - val_acc: 0.9764\n",
      "Epoch 52/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.2963e-07 - acc: 1.0000 - val_loss: 0.2032 - val_acc: 0.9764\n",
      "Epoch 53/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.2875e-07 - acc: 1.0000 - val_loss: 0.2029 - val_acc: 0.9763\n",
      "Epoch 54/1500\n",
      "40000/40000 [==============================] - 4s 97us/step - loss: 1.2823e-07 - acc: 1.0000 - val_loss: 0.2035 - val_acc: 0.9762\n",
      "Epoch 55/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.2747e-07 - acc: 1.0000 - val_loss: 0.2037 - val_acc: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1500\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 1.2693e-07 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9762\n",
      "Epoch 57/1500\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 1.2653e-07 - acc: 1.0000 - val_loss: 0.2036 - val_acc: 0.9763\n",
      "Epoch 58/1500\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.2600e-07 - acc: 1.0000 - val_loss: 0.2040 - val_acc: 0.9764\n",
      "Epoch 59/1500\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.2559e-07 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9763\n",
      "Epoch 60/1500\n",
      "40000/40000 [==============================] - 3s 84us/step - loss: 1.2529e-07 - acc: 1.0000 - val_loss: 0.2042 - val_acc: 0.9763\n",
      "Epoch 61/1500\n",
      "40000/40000 [==============================] - 3s 87us/step - loss: 1.2491e-07 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9760\n",
      "Epoch 62/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2464e-07 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 0.9763\n",
      "Epoch 63/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2436e-07 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9761\n",
      "Epoch 64/1500\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.2397e-07 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9763\n",
      "Epoch 65/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2381e-07 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9763\n",
      "Epoch 66/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2355e-07 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.9763\n",
      "Epoch 67/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2330e-07 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9763\n",
      "Epoch 68/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2308e-07 - acc: 1.0000 - val_loss: 0.2050 - val_acc: 0.9764\n",
      "Epoch 69/1500\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 1.2286e-07 - acc: 1.0000 - val_loss: 0.2048 - val_acc: 0.9764\n",
      "Epoch 70/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2274e-07 - acc: 1.0000 - val_loss: 0.2053 - val_acc: 0.9763\n",
      "Epoch 71/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2254e-07 - acc: 1.0000 - val_loss: 0.2054 - val_acc: 0.9763\n",
      "Epoch 72/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2235e-07 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9763\n",
      "Epoch 73/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2220e-07 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9762\n",
      "Epoch 74/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2207e-07 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9763\n",
      "Epoch 75/1500\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.2194e-07 - acc: 1.0000 - val_loss: 0.2055 - val_acc: 0.9764\n",
      "Epoch 76/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2181e-07 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9762\n",
      "Epoch 77/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2169e-07 - acc: 1.0000 - val_loss: 0.2058 - val_acc: 0.9764\n",
      "Epoch 78/1500\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2159e-07 - acc: 1.0000 - val_loss: 0.2060 - val_acc: 0.9762\n",
      "Epoch 79/1500\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 1.2147e-07 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9763\n",
      "Epoch 80/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2133e-07 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 0.9762\n",
      "Epoch 81/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2129e-07 - acc: 1.0000 - val_loss: 0.2061 - val_acc: 0.9762\n",
      "Epoch 82/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2116e-07 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9763\n",
      "Epoch 83/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 1.2109e-07 - acc: 1.0000 - val_loss: 0.2066 - val_acc: 0.9760\n",
      "Epoch 84/1500\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 1.2103e-07 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9763\n",
      "Epoch 85/1500\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.2092e-07 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9762\n",
      "Epoch 86/1500\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 1.2089e-07 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9762\n",
      "Epoch 87/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2081e-07 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9763\n",
      "Epoch 88/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2074e-07 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 0.9762\n",
      "Epoch 89/1500\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 1.2068e-07 - acc: 1.0000 - val_loss: 0.2067 - val_acc: 0.9761\n",
      "Epoch 90/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2061e-07 - acc: 1.0000 - val_loss: 0.2065 - val_acc: 0.9763\n",
      "Epoch 91/1500\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 1.2054e-07 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9760\n",
      "Epoch 92/1500\n",
      "40000/40000 [==============================] - 4s 101us/step - loss: 1.2051e-07 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9760\n",
      "Epoch 93/1500\n",
      "40000/40000 [==============================] - 3s 83us/step - loss: 1.2046e-07 - acc: 1.0000 - val_loss: 0.2068 - val_acc: 0.9761\n",
      "Epoch 94/1500\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 1.2041e-07 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9761\n",
      "Epoch 95/1500\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.2038e-07 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9761\n",
      "Epoch 96/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2031e-07 - acc: 1.0000 - val_loss: 0.2070 - val_acc: 0.9760\n",
      "Epoch 97/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2027e-07 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9760\n",
      "Epoch 98/1500\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 1.2023e-07 - acc: 1.0000 - val_loss: 0.2072 - val_acc: 0.9762\n",
      "Epoch 99/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2019e-07 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9762\n",
      "Epoch 100/1500\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2015e-07 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9761\n",
      "Epoch 101/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2010e-07 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9761\n",
      "Epoch 102/1500\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.2009e-07 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9761\n",
      "Epoch 103/1500\n",
      "40000/40000 [==============================] - 3s 82us/step - loss: 1.2005e-07 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.9762\n",
      "Epoch 104/1500\n",
      "40000/40000 [==============================] - 4s 89us/step - loss: 1.2002e-07 - acc: 1.0000 - val_loss: 0.2074 - val_acc: 0.9761\n",
      "Epoch 105/1500\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.1999e-07 - acc: 1.0000 - val_loss: 0.2075 - val_acc: 0.9761\n",
      "Epoch 00105: early stopping\n"
     ]
    }
   ],
   "source": [
    "validation_data_split = 0.2\n",
    "num_epochs = 1500\n",
    "model_batch_size = 128\n",
    "tb_batch_size = 20\n",
    "early_patience = 100\n",
    "#tensorboard is used for visualization\n",
    "tensorboard_cb   = TensorBoard(log_dir='logs', batch_size= tb_batch_size, write_graph= True)\n",
    "earlystopping_cb = EarlyStopping(monitor='val_loss', verbose=1, patience=early_patience, mode='min')\n",
    "#Early stopping happens when the quantity monitored stops increasing or decreasing\n",
    "# Read Dataset\n",
    "dataset = training_data\n",
    "\n",
    "# Process Dataset\n",
    "processedData, processedLabel = processData(dataset)\n",
    "history = model.fit(processedData\n",
    "                    , processedLabel\n",
    "                    , validation_split=validation_data_split\n",
    "                    , epochs=num_epochs\n",
    "                    , batch_size=model_batch_size\n",
    "                    , callbacks = [tensorboard_cb,earlystopping_cb]\n",
    "                   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1c37d68dd8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c37ee4198>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c37f232b0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1c37f39860>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c37e7cc50>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(history.history)\n",
    "df.plot(subplots=True, grid=True, figsize=(10,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN on mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9821\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.predict(test_data[0])\n",
    "\n",
    "right = 0\n",
    "predNN = []\n",
    "for i in range(10000):\n",
    "    \n",
    "    m = np.argmax(eval_results[i])\n",
    "    predNN.append(m)\n",
    "    if (m == test_data[1][i]):\n",
    "            right = right + 1\n",
    "accuracy = right/10000\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN on USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.0950228e-14 0.0000000e+00 6.1434344e-28 ... 1.0001681e-09\n",
      "  4.1643047e-18 9.7595023e-07]\n",
      " [5.4831099e-04 8.9696761e-32 1.3242395e-05 ... 4.8334823e-17\n",
      "  6.9710011e-25 3.2781527e-18]\n",
      " [9.9998605e-01 4.6866350e-27 1.0329853e-15 ... 1.3935022e-05\n",
      "  8.1362345e-20 8.2789940e-22]\n",
      " ...\n",
      " [6.4100331e-12 1.3907077e-20 2.4975211e-08 ... 1.8122680e-02\n",
      "  2.6887601e-09 1.2947954e-04]\n",
      " [2.9170544e-24 3.8441018e-11 3.0278934e-16 ... 4.4634257e-06\n",
      "  1.3898868e-09 9.9999559e-01]\n",
      " [8.1267632e-20 5.8081291e-22 3.7722401e-19 ... 1.0000000e+00\n",
      "  4.3471296e-17 7.3234273e-13]]\n",
      "0.4232711635581779\n"
     ]
    }
   ],
   "source": [
    "USPSMat = np.asarray(USPSMat)\n",
    "\n",
    "eval_results = model.predict(USPSMat)\n",
    "\n",
    "right = 0\n",
    "predNNU = []\n",
    "for i in range(19999):\n",
    "    \n",
    "    m = np.argmax(eval_results[i])\n",
    "    predNNU.append(m)\n",
    "    if (m == USPSTar[i]):\n",
    "            right = right + 1\n",
    "accuracy = right/19999\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 533,    0,  236,   80,  106,  215,  268,  267,   34,  261],\n",
       "       [  28,  334,  550,  110,  339,  132,   23,  286,  147,   51],\n",
       "       [  35,    4, 1623,   38,   26,  106,   86,   34,   45,    2],\n",
       "       [  26,   11,  419, 1014,   13,  411,   25,   26,   36,   19],\n",
       "       [  15,   31,  132,   10, 1072,  129,   57,  335,  153,   66],\n",
       "       [  18,    2,  418,   69,    8, 1344,   77,   28,   31,    5],\n",
       "       [  51,   17,  546,   16,   34,  207,  963,  112,   13,   41],\n",
       "       [  16,   69,  180,  438,   52,   50,   46,  929,  213,    7],\n",
       "       [ 157,    4,  242,  309,  146,  317,  220,  182,  396,   27],\n",
       "       [   6,   34,  163,  241,  162,   42,   24,  799,  272,  257]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar\n",
    ">>> y_predict = predNNU\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 971,    0,    1,    0,    0,    0,    4,    1,    3,    0],\n",
       "       [   0, 1126,    2,    1,    0,    0,    2,    1,    3,    0],\n",
       "       [   3,    1, 1014,    1,    3,    0,    2,    5,    3,    0],\n",
       "       [   0,    0,    0,  996,    0,    2,    0,    4,    4,    4],\n",
       "       [   1,    0,    1,    1,  964,    0,    5,    2,    2,    6],\n",
       "       [   2,    0,    0,    7,    2,  871,    3,    2,    3,    2],\n",
       "       [   4,    3,    1,    1,    5,    3,  939,    0,    2,    0],\n",
       "       [   1,    4,    7,    2,    1,    0,    0, 1008,    3,    2],\n",
       "       [   3,    0,    4,    3,    7,    2,    2,    4,  945,    4],\n",
       "       [   2,    3,    0,    2,    6,    3,    1,    4,    1,  987]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true =test_data[1]  \n",
    ">>> y_predict = predNN\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "classifier3 = RandomForestClassifier(n_estimators=10)\n",
    "classifier3.fit(training_data[0], training_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = classifier3.predict(test_data[0])\n",
    "y_pred3.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest on mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.48\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    if (y_pred3[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = right/100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 970,    1,    0,    1,    1,    4,    2,    1,    0,    0],\n",
       "       [   0, 1118,    3,    4,    0,    2,    2,    2,    4,    0],\n",
       "       [   8,    4,  978,   10,    4,    0,    5,   13,    9,    1],\n",
       "       [   1,    0,   17,  953,    0,   21,    1,    6,    9,    2],\n",
       "       [   2,    2,    8,    2,  920,    1,    6,    2,    7,   32],\n",
       "       [   8,    3,    5,   34,    6,  806,   12,    2,   11,    5],\n",
       "       [  10,    3,    3,    2,   11,   12,  914,    0,    3,    0],\n",
       "       [   1,    5,   24,   12,    5,    1,    0,  966,    4,   10],\n",
       "       [   5,    2,   13,   19,    8,   12,    7,    6,  894,    8],\n",
       "       [   9,    5,    5,   12,   23,    7,    1,   11,    7,  929]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1]  \n",
    ">>> y_predict = y_pred3\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest on USPS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30536526826341315\n"
     ]
    }
   ],
   "source": [
    "y_predU = classifier3.predict(USPSMat)\n",
    "y_predU.shape\n",
    "right = 0\n",
    "\n",
    "for i in range(19999):\n",
    "    \n",
    "    if (y_predU[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = right/19999\n",
    "\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 602,   89,  363,   80,  312,  155,  103,  124,   16,  156],\n",
       "       [  60,  526,  172,  184,  106,   89,   59,  755,   29,   20],\n",
       "       [ 155,  122, 1033,  144,   64,  171,   64,  198,   18,   30],\n",
       "       [  80,   78,  272, 1007,   49,  295,   15,  136,   19,   49],\n",
       "       [  59,  219,  145,  132,  781,  189,   23,  336,   50,   66],\n",
       "       [ 181,  102,  241,  246,   70,  923,   49,  121,   23,   44],\n",
       "       [ 323,   99,  353,  100,  142,  355,  457,  104,   25,   42],\n",
       "       [  61,  427,  392,  323,   39,  154,   19,  534,   41,   10],\n",
       "       [ 123,  164,  281,  286,  157,  646,   84,   89,  128,   42],\n",
       "       [  60,  312,  316,  370,  175,  154,   16,  397,   84,  116]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar  \n",
    ">>> y_predict = y_predU\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model for Logistic Regression, Linear SVM, Random Forest and Neural Network for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =[]\n",
    "for i in range(len(y_pred3)):\n",
    "    k = predlog[i]\n",
    "    l = predsvm1[i]\n",
    "    m = predNN[i]\n",
    "    n = y_pred3[i]\n",
    "    listf = [k,l,m,n]\n",
    "    classk = [predlog[i],l,predNN[i],y_pred3[i]].count(k)\n",
    "    classl = [predlog[i],l,predNN[i],y_pred3[i]].count(l)\n",
    "    classm = [predlog[i],l,predNN[i],y_pred3[i]].count(m)\n",
    "    classn = [predlog[i],l,predNN[i],y_pred3[i]].count(n)\n",
    "    \n",
    "    maxim = [classk,classl,classm,classn]\n",
    "    maxim2 = np.argmax(maxim)\n",
    "    final.append(listf[maxim2])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.84938493849386\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "\n",
    "for i in range(9999):\n",
    "    \n",
    "    if (final[i] == test_data[1][i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = (right/9999)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 965,    0,    0,    1,    0,    2,    8,    1,    3,    0],\n",
       "       [   0, 1117,    2,    3,    0,    0,    4,    1,    8,    0],\n",
       "       [   8,    5,  941,   16,    6,    1,    9,   14,   29,    3],\n",
       "       [   2,    0,   14,  950,    0,   17,    1,    9,   11,    6],\n",
       "       [   1,    2,    3,    2,  920,    0,    8,    1,    8,   37],\n",
       "       [   6,    1,    0,   31,    8,  806,   13,    4,   19,    4],\n",
       "       [  10,    3,    2,    2,    8,   14,  917,    0,    2,    0],\n",
       "       [   2,    9,   19,    5,    4,    0,    0,  964,    2,   23],\n",
       "       [   5,    6,    6,   21,    7,   22,   10,   13,  872,   12],\n",
       "       [   6,    6,    1,   11,   17,   13,    0,   19,    3,  933]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = test_data[1] \n",
    ">>> y_predict = final\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Model for Logistic Regression, Linear SVM, Random Forest and Neural Network for USPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 =[]\n",
    "for i in range(19999):\n",
    "    k = predlogU[i]\n",
    "    l = predsvmU[i]\n",
    "    m = predNNU[i]\n",
    "    n = y_predU[i]\n",
    "    listf = [k,l,m,n]\n",
    "    classk = [k,l,m,n].count(k)\n",
    "    classl = [k,l,m,n].count(l)\n",
    "    classm = [k,l,m,n].count(m)\n",
    "    classn = [k,l,m,n].count(n)\n",
    "    \n",
    "    maxim = [classk,classl,classm,classn]\n",
    "    maxim2 = np.argmax(maxim)\n",
    "    final2.append(listf[maxim2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6318815940797\n"
     ]
    }
   ],
   "source": [
    "right = 0\n",
    "\n",
    "for i in range(19999):\n",
    "    \n",
    "    if (final2[i] == USPSTar[i]):\n",
    "            right = right + 1\n",
    "        \n",
    "accuracy = (right/19999)*100\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 555,    4,  341,   98,  158,  173,  116,  208,   79,  268],\n",
       "       [  99,  379,  364,  238,  204,   94,   23,  462,  117,   20],\n",
       "       [ 103,   18, 1427,  107,   30,  111,   73,   77,   37,   16],\n",
       "       [  50,    3,  266, 1222,    3,  337,   15,   51,   31,   22],\n",
       "       [  35,   74,   96,   55,  960,  152,   41,  300,  209,   78],\n",
       "       [  82,   12,  353,  168,   16, 1208,   60,   62,   25,   14],\n",
       "       [ 187,   14,  510,   77,   54,  327,  727,   55,   19,   30],\n",
       "       [ 103,  188,  230,  508,   43,  103,   29,  582,  184,   30],\n",
       "       [ 192,   26,  161,  346,   89,  617,  113,  109,  302,   45],\n",
       "       [  23,  142,  156,  462,  106,   76,   14,  604,  253,  164]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    ">>> y_true = USPSTar\n",
    ">>> y_predict = final2\n",
    ">>> confusion_matrix(y_true, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
